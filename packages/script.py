import hashlib
import json
import os
import re
import subprocess
import sys
import tarfile
import tempfile
import zipfile
from pathlib import Path
from textwrap import dedent

import boto3
import re
import sys
import hashlib
import time
import requests

import import_tests


def normalize(name: str) -> str:
    return re.sub(r"[-_.]+", "-", name).lower()


# See setup.sh
# prerequisite: emsdk, pyodide, packages -> pyodide/packages


def gen_bzl_config(tag: str, dist: Path) -> None:
    bucket_url = f"https://pyodide.edgeworker.net/python-package-bucket/{tag}/"
    github_url = (
        f"https://github.com/cloudflare/pyodide-build-scripts/releases/download/{tag}/"
    )
    lock_bytes = (dist / "pyodide-lock.json").read_bytes()
    lock_hash = hashlib.sha256(lock_bytes).hexdigest()
    zip_bytes = (dist / "pyodide_packages.tar.zip").read_bytes()
    zip_hash = hashlib.sha256(zip_bytes).hexdigest()
    all_wheels_bytes = (dist / "all_wheels.zip").read_bytes()
    all_wheels_hash = hashlib.sha256(all_wheels_bytes).hexdigest()

    with open(dist / "pyodide-lock.json", "r") as file:
        lock = json.load(file)
    packages = [package["name"] for package in lock["packages"].values()]
    imports_to_test = import_tests.gen(packages)

    Path("pyodide_bucket.bzl").write_text(
        dedent(
            f"""
            # Do not edit this file by hand. See docs/pyodide.md for info on how to generate it.
            # These variables are factored out here because they are being shared by the WORKSPACE files in
            # both edgeworker and workerd, as well as src/pyodide/BUILD.bazel

            PYODIDE_PACKAGE_BUCKET_URL = "{bucket_url}"
            PYODIDE_GITHUB_RELEASE_URL = "{github_url}"
            PYODIDE_LOCK_SHA256 = "{lock_hash}"
            PYODIDE_PACKAGES_TAR_ZIP_SHA256 = "{zip_hash}"
            PYODIDE_ALL_WHEELS_ZIP_SHA256 = "{all_wheels_hash}"

            # IMPORTANT: when updating this file in git, check the diff to make sure none of the imports below are being removed unexpectedly

            PYODIDE_IMPORTS_TO_TEST =
            """
        ).strip()
        + " "
        + json.dumps(imports_to_test, indent=3, sort_keys=True)
        + "\n"
    )


# creates a package bundle .tar.zip file to be bundled in with edgeworker
# the resulting bundle is written to dist/pyodide_packages.tar.zip
def make_bundle(tag: str, dist: Path = Path("dist")) -> None:
    with open(dist / "pyodide-lock.json", "r") as file:
        lock = json.load(file)
    with tempfile.TemporaryDirectory(delete=False) as t:
        tempdir = Path(t)
        print("making bundle in " + str(tempdir))
        # copy pyodide-lock.json into tempdir
        with open(tempdir / "pyodide-lock.json", "w") as file:
            json.dump(lock, file)
        for package in lock["packages"].values():
            name = normalize(package["name"])
            print("untarring " + name)
            (tempdir / name).mkdir()
            if name.endswith("-tests") or name == "test":
                continue
            file = dist / package["file_name"]
            with tarfile.open(file, "r:gz") as zip:
                zip.extractall(tempdir / name)
        # create temp tarfile from tempdir
        with tarfile.open(tempdir / "pyodide_packages.tar", "w") as tar:
            tar.add(tempdir, arcname="./")
        # create zip file in dist/ from tarfile
        with zipfile.ZipFile(
            dist / "pyodide_packages.tar.zip", "w", compression=zipfile.ZIP_DEFLATED
        ) as zip:
            zip.write(tempdir / "pyodide_packages.tar", "pyodide_packages.tar")
        # create all_wheels.zip file for testing
        with zipfile.ZipFile(
            dist / "all_wheels.zip", "w", compression=zipfile.ZIP_DEFLATED
        ) as zip:
            for package in lock["packages"].values():
                file = dist / package["file_name"]
                zip.write(file, f"{package['file_name']}")

    gen_bzl_config(tag, dist)


# uploads everything in dist to python-package-bucket at tag/...
def upload_to_r2(tag: str, dist=Path("dist")) -> None:
    # upload to r2
    r2_account_id = os.environ["R2_ACCOUNT_ID"]
    r2_access_key = os.environ.get("R2_ACCESS_KEY_ID")
    r2_secret_access_key = os.environ.get("R2_SECRET_ACCESS_KEY")
    s3 = boto3.client(
        "s3",
        endpoint_url=f"https://{r2_account_id}.r2.cloudflarestorage.com",
        aws_access_key_id=r2_access_key,
        aws_secret_access_key=r2_secret_access_key,
        region_name="auto",
    )

    files_remaining = []

    # upload entire dist directory to r2, excluding all_wheels.zip and pyodide_packages.tar.zip
    for root, dirs, files in os.walk(dist):
        for file in files:
            if file in {"all_wheels.zip", "pyodide_packages.tar.zip"}:
                continue
            path = Path(root) / file
            key = tag + "/" + str(path.relative_to(dist))
            files_remaining.append((path, key))

    # attempt to upload each file 5 times. If after 5 attempts the file is still not accessible at pyodide.edgeworker.net then give up
    ATTEMPTS = 5
    for i in range(ATTEMPTS):
        for path, key in files_remaining:
            print(f"uploading {path} to {key}")
            s3.upload_file(str(path), "python-package-bucket", key)

        new_files_remaining = []

        time.sleep(10)

        for path, key in files_remaining:
            # Construct URL to fetch the uploaded file
            url = f"https://pyodide.edgeworker.net/python-package-bucket/{key}"
            print(f"Checking {url}")

            try:
                # Download the file content from the URL
                response = requests.get(url)
                response.raise_for_status()  # Raise an exception if the status is not 200 OK

                # Read the local file content
                with open(path, "rb") as f:
                    local_content = f.read()

                # Compare contents
                if local_content == response.content:
                    print(f"{path} uploaded successfully.")
                else:
                    print(f"Content mismatch for {path}. Retrying...")
                    new_files_remaining.append((path, key))
            except requests.exceptions.RequestException as e:
                print(f"Failed to verify {path}: {e}. Retrying...")
                new_files_remaining.append((path, key))

        files_remaining = new_files_remaining

        if not files_remaining:
            break

        if i != ATTEMPTS - 1:
            for path, key in files_remaining:
                s3.delete_object(Bucket="python-package-bucket", Key=key)

    if files_remaining:
        raise Exception("Failed to upload packages after 5 attempts: ", files_remaining)


# converts all the .zip wheels into .tar.gz format (destructively)
def convert_wheels_to_tar_gz(dist: Path = Path("dist")) -> None:
    with open(dist / "pyodide-lock.json", "r") as file:
        lock = json.load(file)

    for package in lock["packages"].values():
        file = dist / package["file_name"]
        # check file ends with .zip or .whl
        if not (file.name.endswith(".zip") or file.name.endswith(".whl")):
            continue
        new_file = file.with_suffix(".tar.gz")
        print("Converting zip file " + str(file) + " to .tar.gz format")
        with zipfile.ZipFile(file, "r") as zip:
            with tempfile.TemporaryDirectory() as t:
                tempdir = Path(t)
                zip.extractall(tempdir)
                # create tar.gz file from tempdir
                with tarfile.open(new_file, "w:gz") as tar:
                    tar.add(tempdir, arcname="./")
        file.unlink()
        package["file_name"] = new_file.name
        # update sha256 hash
        new_file_bytes = new_file.read_bytes()
        new_file_hash = hashlib.sha256(new_file_bytes).hexdigest()
        package["sha256"] = new_file_hash

    with open(dist / "pyodide-lock.json", "w") as file:
        json.dump(lock, file)


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python script.py <tag>")
        sys.exit(1)
    tag = sys.argv[1]

    with open("required_packages.txt", "r") as file:
        required_packages = file.read().split("\n")
    result = subprocess.run(
        ["pyodide", "build-recipes", "--install", *required_packages]
    )
    if result.returncode != 0:
        print("Failed to build recipes", file=sys.stderr)
        sys.exit(result.returncode)

    convert_wheels_to_tar_gz()

    make_bundle(tag)
    upload_to_r2(tag)
